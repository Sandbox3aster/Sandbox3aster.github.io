<!DOCTYPE html>
<html lang="en">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-111713571-1"></script>
	<script>
  		window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
  		gtag('js', new Date());
  		gtag('config', 'UA-111713571-1');
	</script>

	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

	<!-- Bootstrap core CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
	<!-- Custom styles for this template -->
	<link href="files/jumbotron.css" rel="stylesheet">
	<script src="js/main.js"></script>
  <script src="js/scroll.js"></script>
</head>

<title>Junru Wu</title>

<body>
	<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark" id="Home">
	    <div class="container">
		<a class="navbar-brand" href="#Home">Junru Wu</a>

		<div class="collapse navbar-collapse" id="navbarToggle">
			<ul class="navbar-nav ml-auto">
				<li class="nav-item">
					<a class="nav-link" href="#Home">Home</a>
				</li>
				<li class="nav-item">
					<a class="nav-link" href="#Publications">Publications</a>
				</li>
                <li class="nav-item">
					<a class="nav-link" href="https://www.instagram.com/sandbox3aster/">Photography</a>
				</li>
                <li class="nav-item">
					<a class="nav-link" href="#Hardware">Hardware</a>
				</li>
			</ul>
		</div>
	    </div>
	</nav>

	<div class="container" style="padding-top: 80px; font-size: 17px">
		<div class="row">
			<div class="col-md-3", style="padding-right: 40px">
				<br>
				<img class="img-responsive img-rounded" src="assets/junruwu.png" alt="" style="max-width: 240px;"><br>
			</div>
			<div class="col-md-9">
			<br>
			<p>I am a final-year PhD Student at <a href="https://vita-group.github.io/" target="_blank">Visual Informatics Group</a> at Texas A&M University, working with <a href="https://www.ece.utexas.edu/people/faculty/atlas-wang" target='_blank'>Prof. Zhangyang Wang</a>. I received my bachelor's degree from <a href="https://en.tongji.edu.cn/" target="_blank">Tongji University</a>.
			</p>

			<p>My research interests lie in the intersection of computer vision and machine learning. In particular, I am interested in enabling efficient machine learning in a board specturm of computer vision problems, which includes the following topics:
			</p>
            <p>
            (i) Modality-Agnostic Multimodal Understanding (Multimodal Pre-training, Multimodal Fusion)<br>
            (ii) Efficient Neural Networks (Neural Architecture Search, Neural Network Compression)<br>
            (iii) Efficient Image Restoration (Image/ Video Deblurring, Denoising)
            </p>
			<p>
			Email: sandboxmaster [at] tamu (dot) edu<br>
			<a href="https://scholar.google.com/citations?user=5wXwjysAAAAJ&hl=en" target="_blank">Google Scholar</a> /
			<a href="https://github.com/Sandbox3aster" target="_blank">GitHub</a> /
			<a href="https://www.linkedin.com/in/junru-wu/" target="_blank">Linkedin</a> /
			<a href="https://drive.google.com/file/d/1ACUoeT4gJ4_Vu0ZdjIluNDFbb4C5P6kn/view?usp=sharing" target="_blank">Resume</a>
			</p>
			<font color="firebrick"><b>I'm looking for Industry Research Scientist / Engineer positions starting at <i>Fall 2022</i> or <i>Spring 2023</i>.</b></font>
			</div>
		</div>
	</div>
	<br>
	

	<div class="container">
		<h3 id="Experience" style="padding-top: 80px; margin-top: -80px;">Experience</h3>
		<ul>
			<li>
				2022.5 - 2022.12, Research Intern, Google Research<a href="https://research.google/"><img src="./assets/google_research.png" style="height:17%; width:17%; margin-top: 5px;" align="right"></a><br>
				Topics: Multimodal New Understanding in JAX<br>
				Advisors: Dr. <a href="" target="_blank">Feng Han</a>, Dr. <a href="" target="_blank"> Tianqi Liu</a>, Dr. <a href="" target="_blank"> Frederick Liu</a>, Dr. <a href="" target="_blank">Hongkun Yu</a>, Dr. <a href="" target="_blank">Jialu Liu</a>
			</li>
			<li>
				2021.5 - 2021.12, Research Intern, Google Research<a href="https://research.google/"><img src="./assets/google_research.png" style="height:17%; width:17%; margin-top: 1px;" align="right"></a><br>
				Topics: Scaling Multimodal Pre-Training to noisy data in the wild<br>
				Advisors: Dr. <a href="" target="_blank">Yi Liang</a>, Dr. <a href="" target="_blank">Feng Han</a>, Dr. <a href="" target="_blank"> Tianqi Liu</a>, Dr. <a href="" target="_blank">Cong Yu</a>
			</li>
			<li>
				2020.5 - 2020.8, Research Intern, Microsoft Research<a href="https://www.microsoft.com/en-us/research/"><img src="./assets/microsoft.png" style="height:13%; width:13%; margin-top: -3px;" align="right"></a><br>
				Topics: Neural Archecture Search with Weak Predictors<br>
				Advisors: Dr. <a href="" target="_blank">Dongdong Chen</a>, Dr. <a href="" target="_blank">Xiyang Dai</a>, Dr. <a href="" target="_blank">Yinpeng Chen</a>, Dr. <a href="" target="_blank">Mengchen Liu</a>, Dr. <a href="" target="_blank">Zicheng Liu</a>, Dr. <a href="" target="_blank">Lu Yuan</a>
			</li>
			<li>
				2019.6 - 2019.12, Research Intern, NEC Lab America<a href="https://www.nec-labs.com/"><img src="./assets/necla.jpg" style="height:16%; width:16%; margin-top: 2.5px;" align="right"></a><br>
				Topics: Video/Image Deblurring, Face Anti-Spoofing<br>
				Advisors: Dr. <a href="" target="_blank">Xiang Yu</a>, Dr. <a href="" target="_blank">Buyu Liu</a>, Prof. <a href="" target="_blank">Manmohan Chandraker</a>
			</li>
			<li>
				2019.3 - 2019.6, Research Intern, ByteDance AI Lab<a href="https://ailab.bytedance.com/"><img src="./assets/bytedance.png" style="height:15%; width:15%; margin-top: 0px;" align="right"></a><br>
				Topics: Video Object Segmentation in TikTok Videos<br>
				Advisors: Dr. <a href="" target="_blank">Ding Liu</a>, Dr. <a href="" target="_blank">Linjie Yang</a>, Dr. <a href="" target="_blank">Chen Fang</a>, Dr. <a href="" target="_blank">Jianchao Yang</a>
			</li>
			<li>
				2016.7 - 2017.8, Research Assistant, ShanghaiTech University<a href="https://sist.shanghaitech.edu.cn/sist_en/"><img src="./assets/shanghaitech.svg" style="height:15%; width:15%; margin-top: 0px;" align="right"></a><br>
				Topics: Personalized Saliency Detection, Saliency in VR<br>
				Advisors: Prof. <a href="" target="_blank">Shenghua Gao</a>, Prof. <a href="" target="_blank">Jingyi Yu</a>
			</li>
		</ul>
	</div><br>

	<!-- Publications -->
	<div class="container">
		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px;">
			Publications
			<small><small>
			(<a href="" id="select0" onclick="showPubs(0); return false;">show selected</a> /
			 <a href="" id="select1" onclick="showPubs(1); return false;">show by date</a> /
       		 <a href="" id="select2" onclick="showPubs(2); return false;">show by topic</a>)
			</small></small><br>

			<small><small>
		  	<font color="black">Research Topics:
				<a href="#multimodal" onclick="showPubs(2)">Multi-Modal Understanding</a> /
				<a href="#neuralnetwork" onclick="showPubs(2)">Efficient Neural Networks</a> /
				<a href="#restoration" onclick="showPubs(2)">Image Restoration</a> /
				<a href="#saliency" onclick="showPubs(2)">Visual Saliency</a> /
				<a href="#biometrics" onclick="showPubs(2)">Biometrics</a>

			</font><br>
			</small></small>
		</h3>

		<div id="pubs"></div>

		<script id="pubs_selected" language="text">
			<font color="black">(* indicates equal contribution)</font><br><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/cmgh/pipeline.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yi Liang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Feng Han</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Hassan Akbari</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Cong Yu</a>
					<br>
					<b><font color="black">Scaling Multimodal Pre-Training via Cross-Modality Gradient Harmonization</font></b>
					<br>
					<b><a href="https://nips.cc/Conferences/2022" target="_blank">NeurIPS 2022</a></b>,
					<a href="https://sandbox3aster.github.io/projects/cmgh/" target="_blank"> <small>[Project]</small></a>
					<a href="https://arxiv.org/abs/2211.02077" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/neurips21_weaknas/pipeline.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiyang Dai</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Dongdong Chen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yinpeng Chen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Mengchen Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ye Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>, 
					<a href="https://sandbox3aster.github.io" target="_blank">Zicheng Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Mei Chen</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Lu Yuan</a>
					<br>
					<b><font color="black">Stronger NAS with Weaker Predictor</font></b>
					<br>
					<b><a href="https://nips.cc/Conferences/2021" target="_blank">NeurIPS 2021</a></b>,
					<a href="https://arxiv.org/abs/2102.10490" target="_blank"> <small>[Paper]</small></a>
					<a href="https://sandbox3aster.github.io" target="_blank"> <small>[Project]</small></a>
					<a href="https://github.com/VITA-Group/WeakNAS" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/WeakNAS?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/wacv20_david/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiang Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ding Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Manmohan Chandraker</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">DAVID: Dual-Attentional Video Deblurring</font></b>
					<br>
					<b><a href="https://openaccess.thecvf.com/WACV2020" target="_blank">WACV 2020</a></b>,
					<a href="https://arxiv.org/abs/1912.03445" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/iccv19_deblurganv2/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Orest Kupyn</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Tetiana Martyniuk</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a> and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<br>
					<b><font color="black">DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better</font></b>
					<br>
					<b><a href="https://iccv2019.thecvf.com/" target="_blank">ICCV 2019</a></b>,
					<a href="https://arxiv.org/abs/1908.03826" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-group/DeblurGANv2" target="_blank"> <small>[Code]</small></a>
					<br>
					<font color="firebrick"><b>Third-party Adaptation:</b></font>
					<a href="https://docs.openvino.ai/latest/omz_models_model_deblurgan_v2.html" target="_blank"> <small>[OpenVINO]</small></a>
					<a href="https://github.com/kritiksoman/GIMP-ML" target="_blank"> <small>[GIMP-ML]</small></a>
					<a href="https://www.youtube.com/watch?v=adgHtu4chyU&list=PLo9r5wFmpD5dLWTyo6NOiD6BJjhfEOM5t&index=4" target="_blank"> <small>[GIMP-ML(Demo)]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/DeblurGANv2?style=social"></img>
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/tpami20_bridging/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Rosaura G. VidalMata</a>,...
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,...
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,...
					<a href="https://sandbox3aster.github.io" target="_blank">Walter J. Scheirer</a>
					<br>
					<b><font color="black">Bridging the gap between computational photography and visual recognition</font></b>
					<br>
					<b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI 2020</a></b>,
					<a href="https://arxiv.org/abs/1901.09482" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-Group/TAMU-PKU-UG2" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/TAMU-PKU-UG2?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/icml18_deepkmeans/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yue Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhenyu Wu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ashok Veeraraghavan</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Yingyan Lin</a>
					<br>
					<b><font color="black">Deep <i>k</i>-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions</font></b>
					<br>
					<b><a href="https://icml.cc/Conferences/2018" target="_blank">ICML 2018</a></b>,
					<a href="https://arxiv.org/abs/1806.09228" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-Group/Deep-K-Means-pytorch" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/Deep-K-Means-pytorch?style=social"></img>
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/tpami18_saliency/teaser1.png" style="border:0px solid black" alt="">
					<img class="img-fluid img-rounded" src="projects/tpami18_saliency/teaser2.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>*
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Nianyi Li</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>

					<br>
					<b><font color="black">Personalized Saliency and Its Prediction</font></b>
					<br>
					<b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI 2018</a></b>,
					<a href="https://arxiv.org/abs/1710.03011" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/Personalized-Saliency" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/Personalized-Saliency?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/ijcai17_saliency/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Nianyi Li</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>
					<br>
					<b><font color="black">Beyond Universal Saliency: Personalized Saliency Prediction with Multi-task CNN</font></b>
					<br>
					<b><a href="https://ijcai-17.org/" target="_blank">IJCAI 2017</a></b>,
					<a href="https://www.ijcai.org/proceedings/2017/0543.pdf" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/Personalized-Saliency" target="_blank"> <small>[Code]</small></a>,
					<font color="firebrick"><b>Best Student Paper Finalist</b></font>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/Personalized-Saliency?style=social"></img>
				</div>
			</div><hr>


		</script>

		
		<script id="pubs_by_date" language="text">
		  <font color="black">(* indicates equal contribution)</font><br><hr>

		  	<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/cmgh/pipeline.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yi Liang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Feng Han</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Hassan Akbari</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Cong Yu</a>
					<br>
					<b><font color="black">Scaling Multimodal Pre-Training via Cross-Modality Gradient Harmonization</font></b>
					<br>
					<b><a href="https://nips.cc/Conferences/2022" target="_blank">NeurIPS 2022</a></b>,
					<a href="https://sandbox3aster.github.io/projects/cmgh/" target="_blank"> <small>[Project]</small></a>
					<a href="https://arxiv.org/abs/2211.02077" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/arxiv22_grasping/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Qiucheng Wu</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Yifan Jiang</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Kai Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Gong Zhang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Humphrey Shi</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Shiyu Chang</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Grasping the Arrow of Time from the Singularity: Decoding Micromotion in Low-dimensional Latent Spaces from StyleGAN</font></b>
					<br>
					<b><a href="https://sandbox3aster.github.io/" target="_blank">Arxiv Preprint</a></b>,
					<a href="https://arxiv.org/abs/2204.12696" target="_blank"> <small>[Paper]</small></a>
					<a href="https://wuqiuche.github.io/micromotion-project-page/" target="_blank"> <small>[Project]</small></a>
					<a href="https://github.com/wuqiuche/micromotion-StyleGAN" target="_blank"> <small>[Code]</small></a>
					<a href="http://128.223.6.65:7860/" target="_blank"> <small>[Demo]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/wuqiuche/micromotion-styleGAN?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/wacv22_autox3d/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yifan Jiang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xinyu Gong</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Humphrey Shi</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhicheng Yan</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Auto-X3D: Ultra-Efficient Video Understanding via Finer-Grained Neural Architecture Search</font></b>
					<br>
					<b><a href="https://wacv2022.thecvf.com/home" target="_blank">WACV 2022</a></b>,
					<a href="https://arxiv.org/abs/2112.04710" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/neurips21_weaknas/pipeline.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiyang Dai</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Dongdong Chen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yinpeng Chen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Mengchen Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ye Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>, 
					<a href="https://sandbox3aster.github.io" target="_blank">Zicheng Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Mei Chen</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Lu Yuan</a>
					<br>
					<b><font color="black">Stronger NAS with Weaker Predictor</font></b>
					<br>
					<b><a href="https://nips.cc/Conferences/2021" target="_blank">NeurIPS 2021</a></b>,
					<a href="https://arxiv.org/abs/2102.10490" target="_blank"> <small>[Paper]</small></a>
					<a href="https://sandbox3aster.github.io" target="_blank"> <small>[Project]</small></a>
					<a href="https://github.com/VITA-Group/WeakNAS" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/WeakNAS?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/wacv20_david/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiang Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ding Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Manmohan Chandraker</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">DAVID: Dual-Attentional Video Deblurring</font></b>
					<br>
					<b><a href="https://openaccess.thecvf.com/WACV2020" target="_blank">WACV 2020</a></b>,
					<a href="https://arxiv.org/abs/1912.03445" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/tpami20_bridging/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Rosaura G. VidalMata</a>,...
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,...
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,...
					<a href="https://sandbox3aster.github.io" target="_blank">Walter J. Scheirer</a>
					<br>
					<b><font color="black">Bridging the gap between computational photography and visual recognition</font></b>
					<br>
					<b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI 2020</a></b>,
					<a href="https://arxiv.org/abs/1901.09482" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-Group/TAMU-PKU-UG2" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/TAMU-PKU-UG2?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/iccv19_deblurganv2/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Orest Kupyn</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Tetiana Martyniuk</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a> and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<br>
					<b><font color="black">DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better</font></b>
					<br>
					<b><a href="https://iccv2019.thecvf.com/" target="_blank">ICCV 2019</a></b>,
					<a href="https://arxiv.org/abs/1908.03826" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-group/DeblurGANv2" target="_blank"> <small>[Code]</small></a>
					<br>
					<font color="firebrick"><b>Third-party Adaptation:</b></font>
					<a href="https://docs.openvino.ai/latest/omz_models_model_deblurgan_v2.html" target="_blank"> <small>[OpenVINO]</small></a>
					<a href="https://github.com/kritiksoman/GIMP-ML" target="_blank"> <small>[GIMP-ML]</small></a>
					<a href="https://www.youtube.com/watch?v=adgHtu4chyU&list=PLo9r5wFmpD5dLWTyo6NOiD6BJjhfEOM5t&index=4" target="_blank"> <small>[GIMP-ML(Demo)]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/DeblurGANv2?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/arxiv20_spoofing/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiang Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Buyu Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Manmohan Chandraker</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Uncertainty-Aware Physically-Guided Proxy Tasks for Unseen Domain
Face Anti-spoofing</font></b>
					<br>
					<b><a href="https://sandbox3aster.github.io/" target="_blank">Arxiv Preprint</a></b>,
					<a href="https://arxiv.org/abs/2011.14054" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/arxiv19_usaid/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Sicheng Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Bihan Wen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Dacheng Tao</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Segmentation-Aware Image Denoising without Knowing True Segmentation</font></b>
					<br>
					<b><a href="https://sandbox3aster.github.io" target="_blank">Arxiv Preprint</a></b>,
					<a href="https://arxiv.org/abs/1905.08965" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/TAMU-VITA/USAID" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/USAID?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/icml18_deepkmeans/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yue Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhenyu Wu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ashok Veeraraghavan</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Yingyan Lin</a>
					<br>
					<b><font color="black">Deep <i>k</i>-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions</font></b>
					<br>
					<b><a href="https://icml.cc/Conferences/2018" target="_blank">ICML 2018</a></b>,
					<a href="https://arxiv.org/abs/1806.09228" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-Group/Deep-K-Means-pytorch" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/Deep-K-Means-pytorch?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/cvpr18_vrgaze/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yanbing Dong</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhengzhong Sun</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhiru Shi</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>
					<br>
					<b><font color="black">Gaze Prediction in Dynamic 360◦ Immersive Videos</font></b>
					<br>
					<b><a href="https://cvpr2018.thecvf.com/" target="_blank">CVPR 2018</a></b>,
					<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Gaze_Prediction_in_CVPR_2018_paper.pdf" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/VR-EyeTracking" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/VR-EyeTracking?style=social"></img>
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/tpami18_saliency/teaser1.png" style="border:0px solid black" alt="">
					<img class="img-fluid img-rounded" src="projects/tpami18_saliency/teaser2.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>*
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Nianyi Li</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>

					<br>
					<b><font color="black">Personalized Saliency and Its Prediction</font></b>
					<br>
					<b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI 2018</a></b>,
					<a href="https://arxiv.org/abs/1710.03011" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/Personalized-Saliency" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/Personalized-Saliency?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/ijcai17_saliency/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Nianyi Li</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>
					<br>
					<b><font color="black">Beyond Universal Saliency: Personalized Saliency Prediction with Multi-task CNN</font></b>
					<br>
					<b><a href="https://ijcai-17.org/" target="_blank">IJCAI 2017</a></b>,
					<a href="https://www.ijcai.org/proceedings/2017/0543.pdf" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/Personalized-Saliency" target="_blank"> <small>[Code]</small></a>,
					<font color="firebrick"><b>Best Student Paper Finalist</b></font>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/Personalized-Saliency?style=social"></img>
				</div>
			</div><hr>

		</script>


		<script id="pubs_by_topic" language="text">
		
			<font color="black">(* indicates equal contribution)</font><br><hr>

			<br>
			<div id="multimodal" style="padding-top: 80px; margin-top: -80px;">
				<h5>Multi-Modal Understanding</h5>
			</div><br>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/cmgh/pipeline.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yi Liang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Feng Han</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Hassan Akbari</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Cong Yu</a>
					<br>
					<b><font color="black">Scaling Multimodal Pre-Training via Cross-Modality Gradient Harmonization</font></b>
					<br>
					<b><a href="https://nips.cc/Conferences/2022" target="_blank">NeurIPS 2022</a></b>,
					<a href="https://sandbox3aster.github.io/projects/cmgh/" target="_blank"> <small>[Project]</small></a>
					<a href="https://arxiv.org/abs/2211.02077" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/arxiv22_grasping/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Qiucheng Wu</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Yifan Jiang</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Kai Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Gong Zhang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Humphrey Shi</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Shiyu Chang</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Grasping the Arrow of Time from the Singularity: Decoding Micromotion in Low-dimensional Latent Spaces from StyleGAN</font></b>
					<br>
					<b><a href="https://sandbox3aster.github.io/" target="_blank">Arxiv Preprint</a></b>,
					<a href="https://arxiv.org/abs/2204.12696" target="_blank"> <small>[Paper]</small></a>
					<a href="https://wuqiuche.github.io/micromotion-project-page/" target="_blank"> <small>[Project]</small></a>
					<a href="https://github.com/wuqiuche/micromotion-StyleGAN" target="_blank"> <small>[Code]</small></a>
					<a href="http://128.223.6.65:7860/" target="_blank"> <small>[Demo]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/wuqiuche/micromotion-styleGAN?style=social"></img>
				</div>
			</div><hr>
			
			
			<br>
			<div id="neuralnetwork" style="padding-top: 80px; margin-top: -80px;">
			  <h5>Efficient Neural Networks</h5>
			</div><br>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/neurips21_weaknas/pipeline.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiyang Dai</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Dongdong Chen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yinpeng Chen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Mengchen Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ye Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>, 
					<a href="https://sandbox3aster.github.io" target="_blank">Zicheng Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Mei Chen</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Lu Yuan</a>
					<br>
					<b><font color="black">Stronger NAS with Weaker Predictor</font></b>
					<br>
					<b><a href="https://nips.cc/Conferences/2021" target="_blank">NeurIPS 2021</a></b>,
					<a href="https://arxiv.org/abs/2102.10490" target="_blank"> <small>[Paper]</small></a>
					<a href="https://sandbox3aster.github.io" target="_blank"> <small>[Project]</small></a>
					<a href="https://github.com/VITA-Group/WeakNAS" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/WeakNAS?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/icml18_deepkmeans/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yue Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhenyu Wu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ashok Veeraraghavan</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Yingyan Lin</a>
					<br>
					<b><font color="black">Deep <i>k</i>-Means: Re-Training and Parameter Sharing with Harder Cluster Assignments for Compressing Deep Convolutions</font></b>
					<br>
					<b><a href="https://icml.cc/Conferences/2018" target="_blank">ICML 2018</a></b>,
					<a href="https://arxiv.org/abs/1806.09228" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-Group/Deep-K-Means-pytorch" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/Deep-K-Means-pytorch?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/wacv22_autox3d/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yifan Jiang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xinyu Gong</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Humphrey Shi</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhicheng Yan</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Auto-X3D: Ultra-Efficient Video Understanding via Finer-Grained Neural Architecture Search</font></b>
					<br>
					<b><a href="https://wacv2022.thecvf.com/home" target="_blank">WACV 2022</a></b>,
					<a href="https://arxiv.org/abs/2112.04710" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<br>
			<div id="restoration" style="padding-top: 80px; margin-top: -80px;">
				<h5>Image Restoration</h5>
			</div><br>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/iccv19_deblurganv2/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Orest Kupyn</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Tetiana Martyniuk</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a> and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,
					<br>
					<b><font color="black">DeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better</font></b>
					<br>
					<b><a href="https://iccv2019.thecvf.com/" target="_blank">ICCV 2019</a></b>,
					<a href="https://arxiv.org/abs/1908.03826" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-group/DeblurGANv2" target="_blank"> <small>[Code]</small></a>
					<br>
					<font color="firebrick"><b>Third-party Adaptation:</b></font>
					<a href="https://docs.openvino.ai/latest/omz_models_model_deblurgan_v2.html" target="_blank"> <small>[OpenVINO]</small></a>
					<a href="https://github.com/kritiksoman/GIMP-ML" target="_blank"> <small>[GIMP-ML]</small></a>
					<a href="https://www.youtube.com/watch?v=adgHtu4chyU&list=PLo9r5wFmpD5dLWTyo6NOiD6BJjhfEOM5t&index=4" target="_blank"> <small>[GIMP-ML(Demo)]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/DeblurGANv2?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/wacv20_david/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiang Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Ding Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Manmohan Chandraker</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">DAVID: Dual-Attentional Video Deblurring</font></b>
					<br>
					<b><a href="https://openaccess.thecvf.com/WACV2020" target="_blank">WACV 2020</a></b>,
					<a href="https://arxiv.org/abs/1912.03445" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/tpami20_bridging/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Rosaura G. VidalMata</a>,...
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,...
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>,...
					<a href="https://sandbox3aster.github.io" target="_blank">Walter J. Scheirer</a>
					<br>
					<b><font color="black">Bridging the gap between computational photography and visual recognition</font></b>
					<br>
					<b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI 2020</a></b>,
					<a href="https://arxiv.org/abs/1901.09482" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/VITA-Group/TAMU-PKU-UG2" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/TAMU-PKU-UG2?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/arxiv19_usaid/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Sicheng Wang</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Bihan Wen</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Dacheng Tao</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Segmentation-Aware Image Denoising without Knowing True Segmentation</font></b>
					<br>
					<b><a href="https://sandbox3aster.github.io" target="_blank">Arxiv Preprint</a></b>,
					<a href="https://arxiv.org/abs/1905.08965" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/TAMU-VITA/USAID" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/VITA-group/USAID?style=social"></img>
				</div>
			</div><hr>


			<br>
			<div id="saliency" style="padding-top: 80px; margin-top: -80px;">
				<h5>Visual Saliency</h5>
			</div><br>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/cvpr18_vrgaze/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Yanbing Dong</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhengzhong Sun</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Zhiru Shi</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>
					<br>
					<b><font color="black">Gaze Prediction in Dynamic 360◦ Immersive Videos</font></b>
					<br>
					<b><a href="https://cvpr2018.thecvf.com/" target="_blank">CVPR 2018</a></b>,
					<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Gaze_Prediction_in_CVPR_2018_paper.pdf" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/VR-EyeTracking" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/VR-EyeTracking?style=social"></img>
				</div>
			</div><hr>


			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/tpami18_saliency/teaser1.png" style="border:0px solid black" alt="">
					<img class="img-fluid img-rounded" src="projects/tpami18_saliency/teaser2.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>*
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>*,
					<a href="https://sandbox3aster.github.io" target="_blank">Nianyi Li</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>

					<br>
					<b><font color="black">Personalized Saliency and Its Prediction</font></b>
					<br>
					<b><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI 2018</a></b>,
					<a href="https://arxiv.org/abs/1710.03011" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/Personalized-Saliency" target="_blank"> <small>[Code]</small></a>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/Personalized-Saliency?style=social"></img>
				</div>
			</div><hr>

			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/ijcai17_saliency/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank">Yanyu Xu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Nianyi Li</a>,
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Jingyi Yu</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Shenghua Gao</a>
					<br>
					<b><font color="black">Beyond Universal Saliency: Personalized Saliency Prediction with Multi-task CNN</font></b>
					<br>
					<b><a href="https://ijcai-17.org/" target="_blank">IJCAI 2017</a></b>,
					<a href="https://www.ijcai.org/proceedings/2017/0543.pdf" target="_blank"> <small>[Paper]</small></a>
					<a href="https://github.com/xuyanyu-shh/Personalized-Saliency" target="_blank"> <small>[Code]</small></a>,
					<font color="firebrick"><b>Best Student Paper Finalist</b></font>
					<br>
					<img src="https://img.shields.io/github/stars/xuyanyu-shh/Personalized-Saliency?style=social"></img>
				</div>
			</div><hr>

			<br>
			<div id="biometrics" style="padding-top: 80px; margin-top: -80px;">
				<h5>Biometrics</h5>
			</div><br>
			
			<div class="row">
				<div class="col-md-3">
					<img class="img-fluid img-rounded" src="projects/arxiv20_spoofing/teaser.png" style="border:0px solid black" alt="">
				</div>
				<div class="col-md-9">
					<a href="https://sandbox3aster.github.io" target="_blank"><b>Junru Wu</b></a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Xiang Yu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Buyu Liu</a>,
					<a href="https://sandbox3aster.github.io" target="_blank">Manmohan Chandraker</a>, and
					<a href="https://sandbox3aster.github.io" target="_blank">Zhangyang Wang</a>
					<br>
					<b><font color="black">Uncertainty-Aware Physically-Guided Proxy Tasks for Unseen Domain
Face Anti-spoofing</font></b>
					<br>
					<b><a href="https://sandbox3aster.github.io/" target="_blank">Arxiv Preprint</a></b>,
					<a href="https://arxiv.org/abs/2011.14054" target="_blank"> <small>[Paper]</small></a>
				</div>
			</div><hr>


		</script>
	

	<!-- Education -->
	<div class="container">
		<h3 id="Education" style="padding-top: 80px; margin-top: -80px;">Education</h3>
		<ul>
			<li>
				2017.9 - Now, Texas A&M University<br>
				Doctor of Philosophy in Computer Science
			</li>
			<li>
				2021.9 - Now, University of Texas at Austin<br>
				Visiting Scholar in Electrical and Computer Engineering
			</li>
			<li>
				2012.9 - 2016.7, Tongji University<br>
				Bachelor of Engineering in Electrical Engineering
			</li>
		</ul>
	</div><br><br>


	<!-- Service -->
	<div class="container">
		<h3 id="Service" style="padding-top: 80px; margin-top: -80px;">Professional Service</h3>
		<ul>
			<li>Conference Reviewer: NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, AAAI, IJCAI</li>
			<li>Journal Reviewer:
				<a href="https://www.computer.org/csdl/journal/tp" target="_blank">IEEE TPAMI</a>,
				<a href="https://cis.ieee.org/publications/t-neural-networks-and-learning-systems" target="_blank">IEEE TNNLS</a>,
				<a href="https://ieee-cas.org/publication/tcsvt" target="_blank">IEEE TSCVT</a>,
				<a href="https://www.sciencedirect.com/journal/neurocomputing" target="_blank">Neurocomputing</a>
			</li>
		</ul>
	</div><br>

	* Cartoon portrait credit to <a href="https://williamyang1991.github.io/" target="_blank">Shuai Yang</a>

	<div class="container">
		<hr>
		<center>
			<footer>
				<p>&copy; Junru Wu 2022</p>
			</footer>
		</center>
	</div>
	<!-- /container -->

	<!-- Bootstrap core JavaScript -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script>showPubs(0);</script>
	<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>
	<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" crossorigin="anonymous"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" crossorigin="anonymous"></script>
</body>

</html>
